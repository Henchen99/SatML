{
    "generation_strat": "Iterative Prompt Generation",
    "attack_type": "jailbreak",
    "version": "1.0.0",

    "engine": "openai",
    "model": "gpt-4o-mini",
    "api_key": "${API_KEY}",

    "max_iterations": 1,
    "expected_cases": 1,

    "sampled_data_json_file_path": "pipeline/data/collected_data/collected_data.json",
    "generated_attack_json_file_path": "pipeline/data/generated_attacks/hc_generated_attacks.json",

    "prompt_template": ""
}